{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find cars on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_images = glob.glob('./training_data/vehicles/*/*/*.png')\n",
    "noncar_images = glob.glob('./training_data/non_vehicles/*/*/*.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set hog parameters, result of hog parameter exploration step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_params = {}\n",
    "hog_params['cspace'] = 'YUV'\n",
    "hog_params['orient'] = 10\n",
    "hog_params['pix_per_cell'] = 16\n",
    "hog_params['cell_per_block'] = 2\n",
    "hog_params['hog_channel'] = \"ALL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train using SVC after getting hog features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hog features...........\n",
      "56.36 Seconds to extract HOG features...\n",
      "Using: 10 orientations 16 pixels per cell and 2 cells per block\n",
      "Feature vector length: 1080\n",
      "1.38 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9837\n",
      "My SVC predicts:  [ 1.  1.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "For these 10 labels:  [ 1.  1.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      "0.02804 Seconds to predict 10 labels with SVC\n",
      "Training done...........\n"
     ]
    }
   ],
   "source": [
    "from vehicle_detection import classifier\n",
    "print('Training with hog features...........')\n",
    "g_svc, hog_svc_data = classifier.train_hog_features(car_images, noncar_images, hog_params)\n",
    "print('Training done...........')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Begin sliding window search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vehicle_detection import sliding_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set parameters for window, final parameters chosen after trial and study done in vehicle_detection_sliding_window.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sliding_window_params = [[400,450,1],[425,475,1],[450,475,1],\n",
    "                           [400,475,1.5],[425,500,1.5],[400,500,1.5],[400,525,1.5],\n",
    "                           [400,600,2],[400,650,2], [450,650,2],\n",
    "                           [400,650,3], [400,700,3]]\n",
    "g_threshold = 10\n",
    "\n",
    "g_colorspace = hog_params['cspace']\n",
    "g_hog_channel = hog_params['hog_channel']\n",
    "g_orient = hog_params['orient']\n",
    "g_pix_per_cell = hog_params['pix_per_cell']\n",
    "g_cell_per_block = hog_params['cell_per_block']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to perform  sliding window search on provided set of window parameters, chosen after trials performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_location_exploration(img, g_sliding_window_params):\n",
    "    car_windows = []\n",
    "    \n",
    "    for params in g_sliding_window_params:\n",
    "        ystart = params[0]\n",
    "        ystop = params[1]\n",
    "        scale = params[2]\n",
    "            \n",
    "        #Detect cars\n",
    "        car_windows.append(sliding_window.detect_cars(img, ystart, ystop, scale, g_svc, g_colorspace, g_hog_channel, \n",
    "                  g_orient, g_pix_per_cell, g_cell_per_block))\n",
    "    return car_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a class to remember the positions of each car detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class carPosition():\n",
    "    def __init__(self, n):\n",
    "        # Number of past frames to be remembered\n",
    "        self.n_frame = n\n",
    "        # car position values of the last n detections\n",
    "        self.recent_car_positions = [] \n",
    "        \n",
    "        \n",
    "    def update_detected_car_data(self, car_positions):\n",
    "        '''\n",
    "        Update the car positions of current frame.\n",
    "        '''\n",
    "        self.recent_car_positions.append(car_positions)\n",
    "        if len(self.recent_car_positions) > self.n_frame:\n",
    "            #Keep latest n_frames\n",
    "            self.recent_car_positions = self.recent_car_positions[len(self.recent_car_positions)-self.n_frame:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_car_pipeline_video(test_image):\n",
    "    '''\n",
    "    Function to process car detection on a video, which makes use of the carPosition class to remmeber\n",
    "    detections from past frames.\n",
    "    '''\n",
    "    car_windows = car_location_exploration(test_image, g_sliding_window_params)\n",
    "    car_positions = [item for sublist in car_windows for item in sublist] \n",
    "    \n",
    "    if len(car_positions)>0:\n",
    "        car_pos.update_detected_car_data(car_positions)\n",
    "    \n",
    "    # Test out the heatmap\n",
    "    heatmap_img = np.zeros_like(test_image[:,:,0])\n",
    "    for positions in car_pos.recent_car_positions:\n",
    "        heatmap_img = sliding_window.add_heat(heatmap_img, positions)\n",
    "   \n",
    "    thresholded_img = sliding_window.apply_threshold(heatmap_img, g_threshold + len(car_pos.recent_car_positions)//2)\n",
    "   \n",
    "    labels = label(thresholded_img)\n",
    "    # Draw bounding boxes on a copy of the image\n",
    "    draw_img = sliding_window.draw_labeled_bboxes(np.copy(test_image), labels)\n",
    " \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on project video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_out.mp4\n",
      "[MoviePy] Writing video project_video_out.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [10:18<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_out.mp4 \n",
      "\n",
      "Wall time: 10min 20s\n"
     ]
    }
   ],
   "source": [
    "car_pos = carPosition(20)\n",
    "from moviepy.editor import VideoFileClip\n",
    "test_out_file = 'project_video_out.mp4'\n",
    "clip_test = VideoFileClip('project_video.mp4')\n",
    "clip_test_out = clip_test.fl_image(detect_car_pipeline_video)\n",
    "%time clip_test_out.write_videofile(test_out_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
